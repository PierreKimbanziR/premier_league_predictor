{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Establishing a baseline score for the model.\n",
    "Before making our predictions, we need to establish a baseline score. Then we will be able to compare the real score of our model with this base score. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing libraries and the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../assets/data/clean_data.csv')\n",
    "df[\"FTR\"].dropna(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining X an Y\n",
    "X = Every feature available before the kick-off  \n",
    "\n",
    "y = The Full time result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "X = df.drop([\"Div\",\"Date\",\"FTR\", \"FTHG\", \"FTAG\", \"HTHG\", \"HTAG\", \"HTR\", \"HS\", \"AS\", \"AST\", \"HF\", \"AF\", \"HC\",'AC', 'HY', 'AY', 'HR', 'AR', \"Numerical_ftr\", \"Numerical_htr\"], axis=1)\n",
    "y = df[\"FTR\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "There are a few steps to take before training the dummy classifier. \n",
    "* Encoding categorical values\n",
    "* Scaling the values\n",
    "* Handling the null values in the dataset  \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Separating categorical values and numerical values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "categorical_features = [col for col in X.select_dtypes(include='object')]\n",
    "numerical_features = [col for col in X.select_dtypes(include='float64')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying transformations to the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Pipelines creation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "full_pipeline = make_column_transformer((num_pipeline, numerical_features), (cat_pipeline, categorical_features))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Data transformation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "X = full_pipeline.fit_transform(X)\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting train/test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "y.isnull().value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False    2280\n",
       "Name: FTR, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making random prediction with the dummy classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "for strategy in ['stratified', 'most_frequent', 'prior', 'uniform']:\n",
    "    dummy = DummyClassifier(strategy=strategy, random_state=42)\n",
    "    dummy.fit(X_train, y_train)\n",
    "    \n",
    "    print( f\" {strategy} : {dummy.score(X_test, y_test)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " stratified : 0.3267543859649123\n",
      " most_frequent : 0.4407894736842105\n",
      " prior : 0.4407894736842105\n",
      " uniform : 0.3223684210526316\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "The baseline score for our model is between 0.30 and 0.45. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('premier_league': venv)"
  },
  "interpreter": {
   "hash": "4c345db352e38550979c7c30640beff657515c98a6e50b2135129104abaf76a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}